# Duplicate Question Classifier (Quora Question Pairs)

Метою даного проєкту є побудова повноцінної системи для автоматичного виявлення дублікатів запитань, яка дозволяє
ідентифікувати, чи мають дві фрази однакове значення — навіть якщо вони сформульовані по-різному. Це завдання є критично
важливим для покращення пошуку, зменшення дублювання контенту та підвищення якості взаємодії користувачів на платформах
типу Quora.

У якості базового підходу використано логістичну регресію з векторизацією тексту методом TF-IDF, що дозволило встановити
стартовий рівень якості моделі. Надалі реалізовано архітектури на основі згорткових та рекурентних нейронних мереж із
використанням GloVe-ембедінгів для семантичного представлення тексту. Для кращого врахування контексту запитань також
інтегровано BERT-модель, яка працює з парою запитань як єдиним контекстом.

Кожна з моделей оцінювалась за метриками F1 та ROC-AUC як на тренувальній, так і на валідаційній вибірках, що дозволило
об’єктивно порівняти здатність до узагальнення. Результати демонструють переваги сучасних трансформерних підходів при
збереженні ефективності простіших рішень.

У фінальній частині реалізовано інтерфейс для передбачення на нових запитаннях та проаналізовано поведінку моделей на
прикладах. Таким чином, проєкт ілюструє повний цикл побудови системи для класифікації дублікатів — від підготовки даних
і створення архітектур до тестування та оцінки результатів.

Для зручності рішення розділення на декілька ноутбуків:

- [1. Exploratory Data Analysis](notebooks/1_eda.ipynb)
- [2. Baseline Model](notebooks/2_baseline_model.ipynb)
- [3. Preprocessing](notebooks/3_preprocessing.ipynb)
- [4. Modeling with GRU](notebooks/4_1_gru_modeling.ipynb)
- [5. Modeling with LSTM](notebooks/4_2_lstm_modeling.ipynb)
- [6. Modeling with CNN](notebooks/4_3_cnn_modeling.ipynb)
- [7. Modeling with BERT](notebooks/4_4_bert_modeling.ipynb)
- [8. Using the model](notebooks/5_model_explaining.ipynb)

## Exploratory Data Analysis (EDA)

Більш детально з дослідженням та отриманими висновками можна ознайомитись [ноутбуці](notebooks/1_eda.ipynb).

Під час дослідницького аналізу даних було здійснено ґрунтовне дослідження структури, вмісту та стилістичних особливостей
запитань. Проведено аналіз пропущених значень, типів ознак, а також вивчено розподіл цільової змінної (`is_duplicate`).
Окрему увагу приділено довжині запитань, їхній симетричності в парах, а також частотному розподілу лексичних одиниць.

EDA дозволив виявити низку характерних патернів у запитаннях:

- **Дублікати** зазвичай мають коротшу, більш лаконічну форму, часто є спрощеними чи переформульованими версіями запиту.
- **Недублікати** частіше містять складніші або деталізованіші формулювання.
- Розподіли довжин у символах і токенах вказують на типовий обсяг запитання — близько 10–11 слів та ~60 символів.
- Частотний аналіз підтвердив наявність ядра поширених слів і довгого "хвоста" рідковживаних термінів — це враховано при
  побудові векторних представлень (встановлено `min_df=3`, `max_features=4000`).

Такий аналіз допоміг краще зрозуміти природу даних і закласти основу для побудови якісної моделі.

## Baseline Model

Більш детально з реалізацією та експериментами можна ознайомитись у [ноутбуці](notebooks/2_baseline_model.ipynb).

На цьому етапі було реалізовано базовий підхід до класифікації дублікатів запитань на основі класичних методів машинного
навчання та векторизації тексту методом TF-IDF.

Було сформовано нову текстову ознаку — **об’єднання пари запитань через спеціальний роздільник `[SEP]`**, що дозволяє
враховувати контекст пари в цілому.

Основні кроки:

- Застосовано **TF-IDF-векторизатор** із кастомною токенізацією (`process_text`) та обмеженням словника (`min_df=3`,
  `max_features=4000`).
- Побудовано два базових класифікатори:
    - **Logistic Regression**
    - **XGBoost**

Оцінка моделей проводилась на незалежному тестовому наборі (`df_test`), який також було трансформовано у відповідні
векторні ознаки.

## Preprocessing for Deep Learning Models

Більш детально з реалізацією можна ознайомитись у відповідному [ноутбуці](notebooks/3_preprocessing.ipynb).

Мета даного етапу — підготувати дані у форматі, зручному для подачі в моделі глибокого навчання, використовуючи
GloVe-ембедінги, паддінг, токенізацію та побудову векторного словника.

Загалом на даному етапі:

- **Побудовано словник токенів** на основі очищених текстів запитань, використовуючи частотний фільтр (`min_freq = 2`)
  та максимальний розмір (`max_size = 50000`).
- **Тексти перетворено в послідовності індексів** відповідно до словника з паддінгом (`<PAD>`) та обмеженням довжини:
    - `max_len = 50` — для обох запитань (`question1`, `question2`)
- **Підготовлені тензори** (`X_q1`, `X_q2`, `y`) збережено у форматі `.pt` для подальшого навчання моделей.
- **Завантажено GloVe-ембедінги** (`glove.6B.300d`) та побудовано матрицю відповідності `embedding_matrix`, яка
  охоплює знайдені слова словника, а для відсутніх використовує випадкову ініціалізацію.
- **Проведено візуалізацію GloVe-векторів** для найбільш поширених токенів у корпусі за допомогою PCA:
    - Побудовано 2D та 3D проєкції embedding-простору.
    - Візуалізація демонструє семантичну близькість слів, що часто зустрічаються у запитаннях.

Цей етап формує повноцінну базу для використання embedding-матриці в подальших експериментах з архітектурами моделей
глибокого навчання.

## Виявлення дублікатів запитань за допомогою GRU-моделі

Більш детально з реалізацією та експериментом можна ознайомитись в [ноутбуці](notebooks/4_1_gru_modeling.ipynb).

Мета цього етапу — розробити та навчити модель на основі двосторонньої GRU (Bidirectional GRU), яка здатна
враховувати послідовну структуру запитань та їхню взаємну семантичну близькість.

Загалом на цьому етапі:

- **Реалізовано кастомну GRU-архітектуру** `QuoraDuplicateGRU`, що складається з:
    - спільного embedding-шару на основі попередньо натренованої матриці GloVe;
    - двостороннього GRU-енкодера для кожного запитання;
    - об’єднання репрезентацій двох запитань через кілька симетричних операцій (concat, difference, multiplication);
    - повнозв’язного шару для прогнозування ймовірності дубліката.

- Навчання заплановано протягом 10 епох, але модель зупинилась на 7-му етапі, через спрацювання механізму ранньої
  зупинки, щоб запобігти подальшому перенавчанню.

GRU-модель показала **високу здатність до узагальнення**, зберігаючи хорошу якість на тестовому наборі. Це дозволяє
перейти до побудови ще складніших архітектур або використовувати ensemble-підходи для подальшого покращення точності.

**Модель схильна до перенавчання.**

## Виявлення дублікатів запитань за допомогою моделі BiLSTM

Більш детально з реалізацією та навчанням можна ознайомитись в [ноутбуці](notebooks/4_2_lstm_modeling.ipynb).

Мета цього етапу — реалізувати глибшу архітектуру на основі двосторонніх LSTM (BiLSTM), здатну вловлювати як семантичний
контекст, так і порядок слів у кожному з запитань окремо.

Загалом на цьому етапі:

- **Реалізовано архітектуру `QuoraLstmDuplicateClassifier`**, яка:
    - використовує спільний embedding-шар на основі GloVe-матриці;
    - має **два окремих двосторонніх LSTM-енкодери** для `question1` і `question2`;
    - отримані вектори репрезентацій об'єднуються (`concat`) і подаються на повнозв’язний шар для передбачення класу.

- **Модель навчалась протягом 10 епох** з використанням Adam-оптимізатора та функції втрат `BCEWithLogitsLoss`.

На відміну від попередньої GRU-моделі, тут **кожне запитання обробляється окремим BiLSTM-енкодером**. Це дозволяє моделі
мати більш гнучке представлення семантики кожного елемента пари, особливо у випадках, коли формулювання суттєво
відрізняються.

**Модель схильна до перенавчання.**

## Виявлення дублікатів запитань за допомогою CNN-моделі

Більш детально з реалізацією можна ознайомитись у [ноутбуці](notebooks/4_3_cnn_modeling.ipynb).

Мета цього етапу — реалізувати компактну та швидку модель на основі згорткової нейронної мережі (CNN), яка ефективно
виділяє ключові локальні шаблони в тексті запитань і порівнює їх.

Загалом на цьому етапі:

- **Реалізовано архітектуру `QuoraDuplicateCNN`**, яка складається з:
- embedding-шару з попередньо натренованими GloVe-векторами;
- спільного **1D-згорткового шару** (`Conv1d`) з подальшим max pooling для стискання інформації;
- окремого енкодингу `question1` та `question2`, кожне проходить через одну і ту ж CNN;
- комбінування репрезентацій через конкатенацію базових операцій;
- класифікаційного шару (`fc`) з dropout для регуляризації.

**Навчання моделі виконано протягом 10 епох** на GPU, з використанням функції втрат `BCEWithLogitsLoss`.

На відміну від RNN-архітектур, CNN-модель є **швидшою у навчанні** та добре працює при обробці текстів фіксованої
довжини. Вона вловлює **локальні патерни** (наприклад, фрази, специфічні словосполучення), що робить її ефективною у
задачах повторюваності запитань, особливо коли формулювання короткі або шаблонні.

**Модель схильна до перенавчання.**

## Виявлення дублікатів із використанням BERT

Більш детально можна ознайомитись у відповідному [ноутбуці](notebooks/4_4_bert_modeling.ipynb).

На цьому етапі було реалізовано трансформерну модель на основі BERT (`bert-base-uncased`), адаптовану під задачу
класифікації пар запитань на дублікати.

Основні компоненти:

- Використано токенізатор і модель `bert-base-uncased` з HuggingFace Transformers.
- Реалізовано кастомний PyTorch-модуль `DuplicateTextClassifier` для гнучкого використання за межами Trainer.
- Для класифікації модель спочатку узагальнює зміст обох запитань, а потім пропускає цю інформацію через два прості
  шари, які допомагають визначити, чи мають запитання однаковий зміст.
- Модель навчалась протягом 3 епох із поступовою зміною швидкості навчання для більшої стабільності. Також
  використовувався пришвидшений режим обчислень, що дозволив зекономити час і ресурси.

| Набір      | F1     | ROC AUC |
|------------|--------|---------|
| Train      | 0.9509 | 0.9915  |
| Validation | 0.8705 | 0.9640  |
| Test       | 0.8695 | 0.9637  |

- Модель демонструє стабільну якість на усіх частинах даних із мінімальним відривом між train та test.
- Незначна перевага по F1 на train свідчить про добру здатність до узагальнення без явного перенавчання.

Дана модель показала найкращий результат.

## Використання натренованої BERT-моделі для передбачення

Більш детально можна ознайомитись у відповідному [ноутбуці](notebooks/5_model_explaining.ipynb).

На даному етапі була проведена валідація, а саме аналіз передбачень вже навченою моделі на нових прикладах пар запитань.
В цілому, модель добре реагує на переформульовані, але синонімічні запитання, також адекватно поводиться з різними, але
близькими за темою парами, а випадку повного дублювання видає максимальну впевненість.

## Результати

В ході реалізації проєкту було побудовано повноцінну систему для задачі виявлення дублікатів запитань, яка охоплює
повний
життєвий цикл ML-проєкту — від аналізу та підготовки даних до побудови моделей, оцінки їх якості та практичного
використання.

Було побудовано декілька підходів — від класичних моделей із TF-IDF до глибоких нейронних мереж на базі
GloVe-ембедінгів, а також BERT-моделі. Для оцінки якості використовувалися метрики F1 та ROC-AUC.

| Модель                                | F1 (Train) | F1 (Test)  | ROC-AUC (Train) | ROC-AUC (Test) |
|---------------------------------------|------------|------------|-----------------|----------------|
| LogisticRegression + TF-IDF           | ~0.84      | ~0.83      | ~0.92           | ~0.92          |
| XGBModel + TF-IDF                     | ~0.86      | ~0.84      | ~0.94           | ~0.93          |
| QuoraDuplicateGRU (BiGRU)             | 0.92       | 0.86       | 0.97            | 0.94           |
| QuoraLstmDuplicateClassifier (BiLSTM) | 0.94       | 0.87       | 0.98            | 0.94           |
| QuoraDuplicateCNN (CNN)               | 0.91       | 0.85       | 0.96            | 0.93           |
| DuplicateTextClassifier (BERT)        | 0.9509     | **0.8695** | 0.9915          | **0.9637**     |

- BERT-модель показує найвищу точність та ROC-AUC на тестових даних — вона найкраще вловлює контекст і семантичну
  подібність між запитаннями.
- BiLSTM-модель демонструє сильну здатність до узагальнення та стабільну якість при меншій складності, ніж BERT.
- GRU та CNN забезпечують хорошу якість при меншому навантаженні на ресурси —.
- Класичні моделі з TF-IDF (Logistic Regression, XGBoost) залишаються конкурентними базовими варіантами, особливо у
  випадках з обмеженими обчислювальними ресурсами.
- Моделі вчаться на семантичних, синтаксичних і структурних ознаках пари запитань, а також ефективно ідентифікують
  переформульовані версії одного змісту.

## Можливі покращення:

На основі отриманих результатів і проведеного аналізу можна сформулювати кілька напрямків для подальшого вдосконалення:

- **Дослідження чутливості** до конкретних шаблонів, типових переформулювань або обманних пар.
- Розробка REST API або Streamlit-інтерфейсу для інтерактивного використання.
